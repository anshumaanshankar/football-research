### Question 1 - What avenue of player acquisition do you think currently provides teams with the most value per dollar spend and why?
The method I used to evaluate a given player's ability in comparison to others in the same position was using a player's overall rating as given on Madden 23. This rating was divided by the log of their salary to give each player a value score. After grouping players by position and obtaining the top 3, it was seen that about 60% of these players signed as free agents, with drafted players being about 30%. This gives us a concise, quick way of what acquisition method provides the most value per dollar spend, as the ratings are good for comparision

However, Madden ratings are a reflection of past performance and do not account for injuries or games played in the season of consideration. In order to overcome this, We can formulate a simple difference in Madden Rating and salary over consecutive years to determine whether a player's current value is on an increasing or decreasing curve. Alternate methods to compare players against each other using a single metric could be using PFF ratings, or to formulate a Wins above replacements (WAR) metric for these players. By using these methods, we might be able to overcome the shortcomings of comparison via Madden rankings.

The working, analysis and visualizations for my chosen approach are available on my GitHub repository: <a> https://github.com/anshumaanshankar/football-research/ </a>

### Question 2 - Imagine that you are tasked with evaluating the accuracy of three different college-to-pro player projection systems for wide receivers. You have both the projections and actual pro statistics for the past 10 seasons. Discuss how you would approach the problem and list any potential issues you may encounter.

From a player-performance standpoint, we can evaluate a system on how well it captures the correlation of key statistics with the outcome or by calculating error metrics such as MAE and RMSE between projection and actual statistics and viewing the distributions of those errors to spot patterns. When comparing algorithms, We can run different statistical tests that compare system accuracies, to arrive at conclusions about which is better (if any). While this would work in comparing most predictive systems, I believe we would not be accounting for all the important factors needed in solving the problem at hand. 

I believe that determining a player's future performance based on the past can be likened to stock value predictions. Just as a stock's value is dependent on the company's valuation and competition, a player's performance depends not only on them, but the atmosphere around them as well. This is exactly what the previously mentioned solution (and models) may fail to consider - factors like past injuries, the player's cultural fit at their new team, the coach's ability to nurture a rookie's talent and squad depth at the WR position on that team, to name some. While these may not be typically captured metrics, finding a way to include such ideas into projection systems would lead to better performing models. For example, adding a negative weight related to squad depth at the WR position and a positive coefficient to playstyle similarity to the player's college team and maybe even player popularity amongst fans (a confidence and morale booster) into existing systems may lead to more accurate results. While this would not work overnight (as these new metrics would have to be defined, calculated and adjusted over time), I believe that models accounting for these off-field factors would yield better results in the long run than those that do not.
